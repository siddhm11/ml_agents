# ðŸ“Š Intelligentâ€¯CSVâ€¯MLâ€¯Agent

Automatically turn **any CSV file** into a productionâ€‘ready machineâ€‘learning model, complete with dataâ€‘quality checks, feature engineering, algorithm selection, hyperâ€‘parameter optimisation and written recommendations â€“ all orchestrated by **LLMâ€‘driven AIâ€¯agents** wired together with **LangGraph**.

---

## Tableâ€¯ofâ€¯Contents
1. [Key Ideas](#key-ideas)
2. [Why LangGraph (â€œLangrathâ€)?](#why-langgraph-langrath)
3. [What Are AIâ€¯Agents?](#what-are-ai-agents)
4. [Highâ€‘level Flow](#high-level-flow)
5. [Detailed Pipeline](#detailed-pipeline)
6. [Project Layout](#project-layout)
7. [QuickÂ Start](#quick-start)
8. [Extending the Agent](#extending-the-agent)
9. [Troubleshooting](#troubleshooting)
10. [License](#license)

---

## Key Ideas
* **Oneâ€‘click ML on tabular data** â€“ just hand the agent a path to a CSV file.
* **Stateful workflow graph** â€“ each step is an explicit node, making debugging and observability easyÂ :contentReference[oaicite:0]{index=0}.
* **LLM assistance** â€“ a Groqâ€‘backed languageâ€‘model client proposes the problem type, preprocessing steps, and even critiques the model resultsÂ :contentReference[oaicite:1]{index=1}.
* **Multiâ€‘model benchmarking** â€“ trains up to four memoryâ€‘efficient algorithms per run and picks the winner based on taskâ€‘appropriate metricsÂ :contentReference[oaicite:2]{index=2}.
* **Dropâ€‘in specialisation** â€“ `RegressionSpecialistAgent` shows how to override just one node to bias the pipeline toward regression problemsÂ :contentReference[oaicite:3]{index=3}.

---

## Why LangGraphÂ (â€œLangrathâ€)?
LangGraph is an openâ€‘source extension of LangChain that treats an agent workflow as an explicit **directed graph**.  
This library was chosen because it provides:

| Benefit | Impact on this project |
|---------|-----------------------|
| **Deterministic routing** | We can declare `csv_loaderÂ â†’Â â€¦Â â†’Â final_recommendation` once and guarantee the same order every run. |
| **State object per run** | The `AgentState` typedâ€‘dict travels through the graph, so every node sees (and may update) the same payloadÂ â€“ no more argument spaghetti. |
| **Easy branching / retries** | Future versions can add e.g. a *â€œdataâ€‘augmentationâ€* branch or loop back for automated reâ€‘training. |
| **Async execution** | Nodes such as LLM calls are `async`, so the pipeline remains responsive. |

In short, LangGraph gives us the **orchestration layer** needed to chain multiple AI agents while keeping the codebase testable and maintainable.

---

## What Are AIâ€¯Agents?
> *â€œAn AI agent is a software entity that observes, reasons and acts autonomously toward a goal.â€*

Inside this repo each **node** is itself an agentâ€‘like function:

| Node (Agent) | Responsibility |
|--------------|----------------|
| **`csv_loader_node`** | Robust CSV ingestion, encoding/delimiter autoâ€‘detection |
| **`initial_inspection_node`** | Basic shape, dtypes, sample rows |
| **`data_quality_assessment_node`** | Missingâ€‘value profiling, outlier detection |
| **`problem_identification_node`** | LLM decides *classificationÂ vsÂ regressionÂ vsÂ clustering* + candidate target column |
| **`feature_analysis_node`** | Hybrid LLM/statistical feature selection |
| **`feature_engineering_node`** | (Placeholder) create interaction terms, PCA, etc. |
| **`algorithm_recommendation_node`** | LLM enumerates best algorithms for the task |
| **`preprocessing_strategy_node`** | Builds the exact imputation/encoding/scaling pipeline |
| **`model_training_node`** | Hyperâ€‘parameter search, crossâ€‘validation, metric logging |
| **`evaluation_analysis_node`** | LLM commentary on results & shortcomings |
| **`final_recommendation_node`** | Endâ€‘toâ€‘end guidance for deployment and next steps |

Because each step is decoupled, you can swap â€œbrainsâ€ (OpenAI, llama.cpp, Huggingâ€¯Face, etc.) or even replace an LLM node with a rulesâ€‘based one and the rest of the graph will still run.

---

## Highâ€‘level Flow

```mermaid
flowchart LR
    A[csv_loader] --> B[initial_inspection]
    B --> C[data_quality_assessment]
    C --> D[problem_identification]
    D --> E[feature_analysis]
    E --> F[feature_engineering]
    F --> G[algorithm_recommendation]
    G --> H[preprocessing_strategy]
    H --> I[model_training]
    I --> J[evaluation_analysis]
    J --> K[final_recommendation]
