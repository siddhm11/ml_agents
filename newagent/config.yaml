# ML Agent Configuration
agent:
  name: "AutoML_LangGraph_Agent"
  version: "1.0.0"
  description: "End-to-end ML pipeline using LangGraph and DeepSeek R1"

# LLM Configuration
llm:
  provider: "groq"
  model: "deepseek-r1-distill-llama-70b"
  api_key_env: "GROQ_API_KEY"
  temperature: 0.1
  max_tokens: 2048

# Data Processing Settings
data:
  max_file_size_mb: 100
  missing_threshold: 0.8  # Drop columns with >80% missing values
  duplicate_threshold: 0.95  # Flag if >95% duplicates
  outlier_method: "iqr"  # "iqr" or "zscore"
  outlier_threshold: 3.0

# Feature Engineering
features:
  polynomial_degree: 2
  max_polynomial_features: 50
  enable_interactions: true
  featuretools_max_depth: 2

# Model Training
model:
  baseline_threshold: 0.6  # Trigger hyperparameter tuning if score < this
  test_size: 0.2
  random_state: 42
  cv_folds: 5
  
  # Optuna settings
  optuna:
    n_trials: 50
    timeout_seconds: 300

# Experiment Tracking
tracking:
  use_mlflow: true
  use_wandb: false  # Set to true if you have wandb account
  experiment_name: "automl_langgraph"

# Logging
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"